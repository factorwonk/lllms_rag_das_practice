{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_t_with_space(documents):\n",
    "    \"\"\"\n",
    "    Replaces all tab characters ('\\t') with spaces in the page content of each document.\n",
    "\n",
    "    Args:\n",
    "        list_of_documents: A list of document objects, each with a 'page_content' attribute.\n",
    "\n",
    "    Returns:\n",
    "        The modified list of documents with tab characters replaced by spaces.\n",
    "    \"\"\"\n",
    "\n",
    "    for doc in documents:\n",
    "        doc.page_content = doc.page_content.replace(\"\\t\", \" \")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context_per_question(question, chunks_query_retriever):\n",
    "    \"\"\"\n",
    "    Retrieves relevant context and unique URLs for a given question using the chunks query retriever.\n",
    "\n",
    "    Args:\n",
    "        question: The question for which to retrieve context and URLs.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - A string with the concatenated content of relevant documents.\n",
    "        - A list of unique URLs from the metadata of the relevant documents.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve relevant documents for the given question\n",
    "    docs = chunks_query_retriever.invoke(question)\n",
    "\n",
    "    # Concatenate document content\n",
    "    # context = \" \".join(doc.page_content for doc in docs)\n",
    "    context = [doc.page_content for doc in docs]\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_context(context):\n",
    "    \"\"\"\n",
    "    Display the contents of the provided context list.\n",
    "\n",
    "    Args:\n",
    "        context (list): A list of context items to be displayed.\n",
    "\n",
    "    Prints each context item in the list with a heading indicating its position.\n",
    "    \"\"\"\n",
    "    for i, c in enumerate(context):\n",
    "        print(f\"Context {i + 1}:\")\n",
    "        print(c)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest the Document\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Document\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pdf(path, hf_model, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Encode a PDF into a vector store using HuggingFace Embedding Model\n",
    "    \"\"\"\n",
    "    # Load PDF documents\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    "    )\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    cleaned_texts = replace_t_with_space(texts)\n",
    "\n",
    "    # Initialize HuggingFace embeddings\n",
    "    hf_embeddings = HuggingFaceEmbeddings(model_name=hf_model)\n",
    "\n",
    "    # Use FAISS.from_documents instead of FAISS.from_texts\n",
    "    vectorstore = FAISS.from_documents(cleaned_texts, hf_embeddings)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "docpath = path\n",
    "hf_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "chunks_vector_store = encode_pdf(path, hf_model, chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Retriever\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "Most of these climate changes are attributed to very small variations in Earth's orbit that \n",
      "change the amount of solar energy our planet receives. During the Holocene epoch, which \n",
      "began at the end of the last ice age, human societies f lourished, but the industrial era has seen \n",
      "unprecedented changes.  \n",
      "Modern Observations  \n",
      "Modern scientific observations indicate a rapid increase in global temperatures, sea levels, \n",
      "and extreme weather events. The Intergovernmental Panel on Climate Change (IPCC) has \n",
      "documented these changes extensively. Ice core samples, tree rings, and ocean sediments \n",
      "provide a historical record that scientists use to understand past climate conditions and \n",
      "predict future trends. The evidence overwhelmingly shows that recent changes are primarily \n",
      "driven by human activities, particularly the emission of greenhou se gases.  \n",
      "Chapter 2: Causes of Climate Change  \n",
      "Greenhouse Gases\n",
      "\n",
      "\n",
      "Context 2:\n",
      "Changing Seasons  \n",
      "Climate change is altering the timing and length of seasons, affecting ecosystems and human \n",
      "activities. For example, spring is arriving earlier, and winters are becoming shorter and \n",
      "milder in many regions. This shift disrupts plant and animal life cycles a nd agricultural \n",
      "practices.  \n",
      "Melting Ice and Rising Sea Levels  \n",
      "Warmer temperatures are causing polar ice caps and glaciers to melt, contributing to rising \n",
      "sea levels. Sea levels have risen by about 20 centimeters (8 inches) in the past century, \n",
      "threatening coastal communities and ecosystems.  \n",
      "Polar Ice Melt\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is the main cause of climate change?\"\n",
    "context = retrieve_context_per_question(test_query, chunks_query_retriever)\n",
    "show_context(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lllms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
